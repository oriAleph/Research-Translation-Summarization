{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d528051f44ab4bd983fc46b86580090d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0931a363f024add845f31ddfdc9a719",
              "IPY_MODEL_69c38902813e4b609f9128278fc12c13",
              "IPY_MODEL_d8b8075438d24ff79ca8d244ff78c33f",
              "IPY_MODEL_b684fa47deb64333818223fdb6f6b403"
            ],
            "layout": "IPY_MODEL_b66e8688846846309ad2c48343ccda85"
          }
        },
        "b0931a363f024add845f31ddfdc9a719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e6a3859ef742d09cbccb482ca6c1fe",
            "placeholder": "​",
            "style": "IPY_MODEL_0064881177d64029b518dfe99badee90",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "69c38902813e4b609f9128278fc12c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f18713f617e74db184d9744fa2c008ed",
            "placeholder": "​",
            "style": "IPY_MODEL_4db246b0cca64d8f884f791f8267656c",
            "value": ""
          }
        },
        "d8b8075438d24ff79ca8d244ff78c33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a931ad1bb14b4508881760c6002cc701",
            "style": "IPY_MODEL_d79e61b3009d4be199f73a31da2173d7",
            "tooltip": ""
          }
        },
        "b684fa47deb64333818223fdb6f6b403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8cc046cdbc4bfa8336c8d29f1ef9de",
            "placeholder": "​",
            "style": "IPY_MODEL_622ec5711c8c4c85a409c6c91fff11c5",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "b66e8688846846309ad2c48343ccda85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "f2e6a3859ef742d09cbccb482ca6c1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0064881177d64029b518dfe99badee90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f18713f617e74db184d9744fa2c008ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db246b0cca64d8f884f791f8267656c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a931ad1bb14b4508881760c6002cc701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79e61b3009d4be199f73a31da2173d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5e8cc046cdbc4bfa8336c8d29f1ef9de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622ec5711c8c4c85a409c6c91fff11c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4a7b00c72d74d808f0246b4caaec996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4fd22bdb135450980a38471eb41efdc",
              "IPY_MODEL_01f48dc1e3004ff2952280ad40d7b9e4",
              "IPY_MODEL_fdb1a9f1930346239aba4c0866afc6bf"
            ],
            "layout": "IPY_MODEL_5b99aec09c054d0399d07ee4787b4ad3"
          }
        },
        "e4fd22bdb135450980a38471eb41efdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ed19de405f4b8cb58e15a5ec8928e5",
            "placeholder": "​",
            "style": "IPY_MODEL_6188f686343e405298dfd79b21d18d97",
            "value": "Downloading builder script: "
          }
        },
        "01f48dc1e3004ff2952280ad40d7b9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fff64806fca4d6aa7fd9c8ba8bff959",
            "max": 2160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b435e27b823e411e9b8f775ea4c0137c",
            "value": 2160
          }
        },
        "fdb1a9f1930346239aba4c0866afc6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1aeef6c385b42c484973100866f177a",
            "placeholder": "​",
            "style": "IPY_MODEL_c66c315361fd42acb1324da77f8a7179",
            "value": " 5.60k/? [00:00&lt;00:00, 190kB/s]"
          }
        },
        "5b99aec09c054d0399d07ee4787b4ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ed19de405f4b8cb58e15a5ec8928e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6188f686343e405298dfd79b21d18d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fff64806fca4d6aa7fd9c8ba8bff959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b435e27b823e411e9b8f775ea4c0137c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1aeef6c385b42c484973100866f177a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c66c315361fd42acb1324da77f8a7179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWsLBSCynPBH",
        "outputId": "386b81f4-ba33-4987-c9c6-50d9c6a4dfd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./NIPS_archive.zip\n",
            "  inflating: authors.csv             \n",
            "  inflating: papers.csv              \n"
          ]
        }
      ],
      "source": [
        "!unzip ./NIPS_archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install rouge-score nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPgUYv3-qb-a",
        "outputId": "27b245bc-2f27-4722-fb13-1827584cc9bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Collecting dill<0.3.6\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 90.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 65.6 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 80.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 84.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 77.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, dill, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "Successfully installed datasets-2.6.1 dill-0.3.5.1 huggingface-hub-0.10.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.2 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=ba9f2dea60265c2565ec7842d2bd2b2caf1176cccdc2a09f8918bd9c39418f0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ooSrpOqOqrc7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make hugging face dataset from NIPS papers.csv\n",
        "df = pd.read_csv('papers.csv', index_col =\"title\")"
      ],
      "metadata": {
        "id": "Ypf0mS_ko_x1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get rid of all the papers that do NOT have an abstract\n",
        "for ind in df.index:\n",
        "  if pd.isnull(df.loc[ind, 'abstract']) or pd.isnull(df.loc[ind, 'full_text']):\n",
        "    df.drop(ind, inplace = True)"
      ],
      "metadata": {
        "id": "uZxbspClkK6_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "69f8DCSbd3N3",
        "outputId": "63dce8f2-719e-4ca1-8329-c4ffe8dd5e63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    source_id  year  \\\n",
              "title                                                                 \n",
              "Learning Generative Models with the Up Propagat...       5220  1997   \n",
              "A Neural Network Based Head Tracking System              5221  1997   \n",
              "Algorithms for Non-negative Matrix Factorization         1861  2000   \n",
              "Characterizing Neural Gain Control using Spike-...       1975  2001   \n",
              "Compressed Regression                                     195  2007   \n",
              "...                                                       ...   ...   \n",
              "Discrete Object Generation with Reversible Indu...       5452  2019   \n",
              "Adaptively Aligned Image Captioning via Adaptiv...       4799  2019   \n",
              "Fully Dynamic Consistent Facility Location               1827  2019   \n",
              "Efficient Rematerialization for Deep Networks            8693  2019   \n",
              "Flow-based Image-to-Image Translation with Feat...       2302  2019   \n",
              "\n",
              "                                                                                             abstract  \\\n",
              "title                                                                                                   \n",
              "Learning Generative Models with the Up Propagat...  Up-\u0002propagation is an algorithm for inverting ...   \n",
              "A Neural Network Based Head Tracking System         We have constructed an inexpensive video based...   \n",
              "Algorithms for Non-negative Matrix Factorization    Non-negative matrix factorization (NMF) has pr...   \n",
              "Characterizing Neural Gain Control using Spike-...  Spike-triggered averaging techniques are effec...   \n",
              "Compressed Regression                               Recent research has studied the role of sparsi...   \n",
              "...                                                                                               ...   \n",
              "Discrete Object Generation with Reversible Indu...  The success of generative modeling in continuo...   \n",
              "Adaptively Aligned Image Captioning via Adaptiv...  Recent neural models for image captioning usua...   \n",
              "Fully Dynamic Consistent Facility Location          We consider classic clustering problems in ful...   \n",
              "Efficient Rematerialization for Deep Networks       When training complex neural networks, memory ...   \n",
              "Flow-based Image-to-Image Translation with Feat...  Learning non-deterministic dynamics and intrin...   \n",
              "\n",
              "                                                                                            full_text  \n",
              "title                                                                                                  \n",
              "Learning Generative Models with the Up Propagat...  Learning Generative Models with the\\n\\nUp(cid:...  \n",
              "A Neural Network Based Head Tracking System         A Neural Network Based\\n\\nHead Tracking System...  \n",
              "Algorithms for Non-negative Matrix Factorization    Algorithms for Non-negative Matrix \\n\\nFactori...  \n",
              "Characterizing Neural Gain Control using Spike-...  Characterizing neural gain control using\\n\\nsp...  \n",
              "Compressed Regression                               Compressed Regression\\n\\nShuheng Zhou∗ John La...  \n",
              "...                                                                                               ...  \n",
              "Discrete Object Generation with Reversible Indu...  Discrete Object Generation\\n\\nwith Reversible ...  \n",
              "Adaptively Aligned Image Captioning via Adaptiv...  Adaptively Aligned Image Captioning via\\n\\nAda...  \n",
              "Fully Dynamic Consistent Facility Location          Fully Dynamic Consistent Facility Location\\n\\n...  \n",
              "Efficient Rematerialization for Deep Networks       Efﬁcient Rematerialization for Deep Networks\\n...  \n",
              "Flow-based Image-to-Image Translation with Feat...  Flow-based Image-to-Image Translation\\n\\nwith ...  \n",
              "\n",
              "[6360 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f17b959c-55f7-46ee-b009-74eec3923b47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>year</th>\n",
              "      <th>abstract</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Learning Generative Models with the Up Propagation Algorithm</th>\n",
              "      <td>5220</td>\n",
              "      <td>1997</td>\n",
              "      <td>Up-\u0002propagation is an algorithm for inverting ...</td>\n",
              "      <td>Learning Generative Models with the\\n\\nUp(cid:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A Neural Network Based Head Tracking System</th>\n",
              "      <td>5221</td>\n",
              "      <td>1997</td>\n",
              "      <td>We have constructed an inexpensive video based...</td>\n",
              "      <td>A Neural Network Based\\n\\nHead Tracking System...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Algorithms for Non-negative Matrix Factorization</th>\n",
              "      <td>1861</td>\n",
              "      <td>2000</td>\n",
              "      <td>Non-negative matrix factorization (NMF) has pr...</td>\n",
              "      <td>Algorithms for Non-negative Matrix \\n\\nFactori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Characterizing Neural Gain Control using Spike-triggered Covariance</th>\n",
              "      <td>1975</td>\n",
              "      <td>2001</td>\n",
              "      <td>Spike-triggered averaging techniques are effec...</td>\n",
              "      <td>Characterizing neural gain control using\\n\\nsp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Compressed Regression</th>\n",
              "      <td>195</td>\n",
              "      <td>2007</td>\n",
              "      <td>Recent research has studied the role of sparsi...</td>\n",
              "      <td>Compressed Regression\\n\\nShuheng Zhou∗ John La...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Discrete Object Generation with Reversible Inductive Construction</th>\n",
              "      <td>5452</td>\n",
              "      <td>2019</td>\n",
              "      <td>The success of generative modeling in continuo...</td>\n",
              "      <td>Discrete Object Generation\\n\\nwith Reversible ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adaptively Aligned Image Captioning via Adaptive Attention Time</th>\n",
              "      <td>4799</td>\n",
              "      <td>2019</td>\n",
              "      <td>Recent neural models for image captioning usua...</td>\n",
              "      <td>Adaptively Aligned Image Captioning via\\n\\nAda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fully Dynamic Consistent Facility Location</th>\n",
              "      <td>1827</td>\n",
              "      <td>2019</td>\n",
              "      <td>We consider classic clustering problems in ful...</td>\n",
              "      <td>Fully Dynamic Consistent Facility Location\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Efficient Rematerialization for Deep Networks</th>\n",
              "      <td>8693</td>\n",
              "      <td>2019</td>\n",
              "      <td>When training complex neural networks, memory ...</td>\n",
              "      <td>Efﬁcient Rematerialization for Deep Networks\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow-based Image-to-Image Translation with Feature Disentanglement</th>\n",
              "      <td>2302</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning non-deterministic dynamics and intrin...</td>\n",
              "      <td>Flow-based Image-to-Image Translation\\n\\nwith ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6360 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f17b959c-55f7-46ee-b009-74eec3923b47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f17b959c-55f7-46ee-b009-74eec3923b47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f17b959c-55f7-46ee-b009-74eec3923b47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataframe into sets\n",
        "train_set, test_set = train_test_split(df, test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "train = Dataset.from_pandas(train_set)\n",
        "test = Dataset.from_pandas(test_set)\n",
        "\n",
        "dataset_tuning = DatasetDict()\n",
        " \n",
        "dataset_tuning['train'] = train\n",
        "dataset_tuning['test'] = test\n",
        "\n",
        "dataset_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC2ywKEPjRwp",
        "outputId": "f41fc1e5-a3cb-4d46-c473-22a7123c607f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['source_id', 'year', 'abstract', 'full_text', 'title'],\n",
              "        num_rows: 5088\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['source_id', 'year', 'abstract', 'full_text', 'title'],\n",
              "        num_rows: 1272\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_tuning['train'][0][\"full_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAyTzH8f1ISU",
        "outputId": "00543fad-90a3-4ed3-bdd1-b45dde3abf73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One Sketch For All: Theory and Application of\n",
            "\n",
            "Conditional Random Sampling\n",
            "\n",
            "Ping Li\n",
            "\n",
            "Dept. of Statistical Science\n",
            "\n",
            "Cornell University\n",
            "\n",
            "Kenneth W. Church\n",
            "Microsoft Research\n",
            "Microsoft Corporation\n",
            "\n",
            "Trevor J. Hastie\n",
            "Dept. of Statistics\n",
            "Stanford University\n",
            "\n",
            "pingli@cornell.edu\n",
            "\n",
            "church@microsoft.com\n",
            "\n",
            "hastie@stanford.edu\n",
            "\n",
            "Abstract\n",
            "\n",
            "Conditional Random Sampling (CRS) was originally proposed for efﬁciently\n",
            "computing pairwise (l2, l1) distances, in static, large-scale, and sparse data. This\n",
            "study modiﬁes the original CRS and extends CRS to handle dynamic or stream-\n",
            "ing data, which much better reﬂect the real-world situation than assuming static\n",
            "data. Compared with many other sketching algorithms for dimension reductions\n",
            "such as stable random projections, CRS exhibits a signiﬁcant advantage in that it\n",
            "is “one-sketch-for-all.” In particular, we demonstrate the effectiveness of CRS in\n",
            "efﬁciently computing the Hamming norm, the Hamming distance, the lp distance,\n",
            "and the χ2 distance. A generic estimator and an approximate variance formula are\n",
            "also provided, for approximating any type of distances.\n",
            "We recommend CRS as a promising tool for building highly scalable systems, in\n",
            "machine learning, data mining, recommender systems, and information retrieval.\n",
            "\n",
            "1 Introduction\n",
            "Learning algorithms often assume a data matrix A ∈ Rn×D with n observations and D attributes\n",
            "and operate on the data matrix A through pairwise distances. The task of computing and maintaining\n",
            "distances becomes non-trivial, when the data (both n and D) are large and possibly dynamic.\n",
            "For example, if A denotes a term-doc matrix at Web scale with each row representing one Web page,\n",
            "then n ≈ O(1010) (which may be veriﬁed by querying “A” or “The” in a search engine). Assuming\n",
            "105 English words, the simplest uni-gram model requires the dimension D ≈ O(105); and a bi-gram\n",
            "model can boost the dimension to D ≈ O(1010). Google book search program currently provides\n",
            "data sets on indexed digital books up to ﬁve-grams. Note that the term-doc matrix is “transposable,”\n",
            "meaning that one can treat either documents or terms as features, depending on applications.\n",
            "Another example is the image data. The Caltech 256 benchmark contains n = 30, 608 images,\n",
            "provided by two commercial ﬁrms. Using pixels as features, a 1024 × 1024 color image can be\n",
            "represented by a vector of dimension D = 10242×3 = 3, 145, 728. Using histogram-based features\n",
            "(e.g., [3]), D = 2563 = 16, 777, 216 is possible if one discretizes the RGB space into 2563 scales.\n",
            "Text data are large and sparse, as most terms appear only in a small fraction of documents. For\n",
            "example, a search engine reports 107 pagehits for the query “NIPS,” which is not common to the\n",
            "general audience. Out of 1010 pages, 107 pagehits indicate a sparsity of 99.9%. (We deﬁne sparsity\n",
            "as the percentage of zero elements.) In the absolute magnitude, however, 107 is actually very large.\n",
            "Not all large-scale data are sparse. Image data are usually sparse when features are represented by\n",
            "histograms; they are, however, dense when pixel-based features are used.\n",
            "\n",
            "1.1 Pairwise Distances Used in Machine Learning\n",
            "The lp distance and χ2 distance are both popular. Denote by u1 and u2 the leading two rows in\n",
            "A ∈ Rn×D. The lp distance (raised to the pth power), and the χ2 distance, are, respectively,\n",
            "\n",
            "dp(u1, u2) =\n",
            "\n",
            "dχ2 (u1, u2) =\n",
            "\n",
            "(u1,i − u2,i)2\n",
            "u1,i + u2,i\n",
            "\n",
            ",\n",
            "\n",
            "(\n",
            "\n",
            "0\n",
            "0\n",
            "\n",
            "= 0).\n",
            "\n",
            "D(cid:88)\n",
            "\n",
            "i=1\n",
            "\n",
            "21/β\n",
            "\n",
            "D(cid:88)\n",
            "\n",
            "i=1\n",
            "\n",
            "|u1,i − u2,i|p,\n",
            "(cid:179)\n",
            "\n",
            "uα\n",
            "1,i + uα\n",
            "2,i\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "(cid:180)1/α − 21/α\n",
            "\n",
            "21/α − 21/β\n",
            "\n",
            "D(cid:88)\n",
            "\n",
            "i=1\n",
            "\n",
            "(cid:180)1/β\n",
            "\n",
            "The χ2 distance is only a special case of Helbertian metrics, deﬁned as,\n",
            "\n",
            "dH,α,β (u1, u2) =\n",
            "\n",
            "uβ\n",
            "1,i + uβ\n",
            "2,i\n",
            "\n",
            ", α ∈ [1, ∞), β ∈ [1/2, α] or β ∈ [−∞, −1].\n",
            "\n",
            "\fHelbertian metrics are deﬁned over probability space[7] and hence suitable for data generated from\n",
            "histograms, e.g., the “bag-of-words” model. For applications in text and images using SVM, empir-\n",
            "ical studies have demonstrated the superiority of Helbertian metrics over lp distances[3, 7, 9].\n",
            "More generally, we are interested in any linear summary statistics which can be written in the form:\n",
            "\n",
            "D(cid:88)\n",
            "\n",
            "dg(u1, u2) =\n",
            "\n",
            "g(u1,i, u2,i),\n",
            "\n",
            "(1)\n",
            "\n",
            "i=1\n",
            "\n",
            "for any generic function g. An efﬁcient method for computing (1) for any g would be desirable.\n",
            "\n",
            "1.2 Bottleneck in Distance/Kernel-based Learning Algorithms\n",
            "A ubiquitous task in learning is to compute, store, update, and retrieve various types of distances[17].\n",
            "For popular kernel SVM solvers including the SMO algorithm[16], storing and computing kernels\n",
            "is the major bottleneck[2], because computing kernels is expensive, and more seriously, storing the\n",
            "full kernel matrix in memory is infeasible when the number of observations n > 105.\n",
            "One popular strategy is to evaluate kernels on the ﬂy[2]. This works well in low-dimensional data\n",
            "(i.e., relatively small D). With high-dimensional data, however, either computing distances on-\n",
            "demand becomes too slow or the data matrix A ∈ Rn×D itself may not ﬁt in memory.\n",
            "We should emphasize that this challenge is a universal issue in distance-based methods, not limited\n",
            "to SVMs. For example, popular clustering algorithms and multi-dimensional scaling algorithms\n",
            "require frequently accessing a (di)similarity matrix, which is usually distance-based.\n",
            "In addition to computing and storing distances, another general issue is that, for many real-world\n",
            "applications, entries of the data matrix may be frequently updated, for example, data streams[15].\n",
            "There have been considerable studies on learning from dynamic data, e.g., [5, 1]. Since streaming\n",
            "data are often not stored (even on disks), computing and updating distances becomes challenging.\n",
            "\n",
            "1.3 Contributions and Paper Organization\n",
            "Conditional Random Sampling (CRS)[12, 13] was originally proposed for efﬁciently computing\n",
            "pairwise (l2 and l1) distances, in large-scale static data. The contributions of this paper are:\n",
            "\n",
            "1. We extend CRS to handle dynamic data. For example, entries of a matrix may vary over\n",
            "time, or the data matrix may not be stored at all. We illustrate that CRS has the one-sketch-\n",
            "for-all property, meaning that the same set of samples/sketches can be used for computing\n",
            "any linear summary statistics (1). This is a signiﬁcant advantage over many other dimen-\n",
            "sion reduction or data stream algorithms.\n",
            "For example, the method of stable random\n",
            "projections (SRP)[8, 10, 14] was designed for estimating the lp norms/distances for a ﬁxed\n",
            "p with 0 < p ≤ 2. Recently, a new method named Compressed Counting[11] is able to\n",
            "very efﬁciently approximate the lp moments of data streams when p ≈ 1.\n",
            "\n",
            "2. We introduce a modiﬁcation to the original CRS and theoretically justify that this mod-\n",
            "iﬁcation makes CRS rigorous, at least for computing the Hamming norm, an important\n",
            "application in databases. We point out the original CRS was based on a heuristic argument.\n",
            "3. We apply CRS for computing Hilbertian metrics[7], a popular family of distances for con-\n",
            "structing kernels in SVM. We focus on a special case, by demonstrating that CRS is effec-\n",
            "tive in approximating the χ2 distance.\n",
            "\n",
            "Section 2 reviews the original CRS. Section 3 extends CRS to dynamic/streaming data. Section 4\n",
            "focuses on using CRS to estimate the Hamming norm of a single vector, based on which Section 5\n",
            "provides a generic estimation procedure for CRS, for estimating any linear summary statistics, with\n",
            "the focus on the Hamming distance and the χ2 distance. Finally, Section 6 concludes the paper.\n",
            "\n",
            "2 Conditional Random Sampling (CRS), the Original Version\n",
            "Conditional Random Sampling (CRS)[12, 13] is a local sampling strategy. Since distances are local\n",
            "(i.e., one pair at a time), there is no need to consider the whole matrix at one time.\n",
            "As the ﬁrst step, CRS applies a random permutation on the columns of A ∈ Rn×D. Figure 1(a)\n",
            "provides an example of a column-permuted data matrix. The next step of CRS is to construct a\n",
            "\n",
            "\fsketch for each row of the data matrix. A sketch can be viewed as a linked list which stores a small\n",
            "fraction of the non-zero entries from the front of each row. Figure 1(b) demonstrates three sketches\n",
            "corresponding to the three rows of the (column) permuted data matrix in Figure 1(a).\n",
            "\n",
            "(a) Permuted data matrix\n",
            "\n",
            "(b) Sketches\n",
            "\n",
            "Figure 1: (a): A data matrix with three rows and D = 16 columns. We assume the columns are\n",
            "already permuted. (b): Sketches are the ﬁrst ki non-zero entries ascending by IDs (here ki = 4).\n",
            "In Figure 1, the sketch for row ui is denoted by Ki. Each element of Ki is a tuple “ID {val},” where\n",
            "“ID” is the column ID after the permutation and “{val}” is the value of that entry.\n",
            "Consider two rows u1 and u2. The last (largest) IDs of sketches K1 and K2 are max(ID(K1)) = 10\n",
            "and max(ID(K2)) = 8, respectively. Here, “ID(K)” stands for the vector of IDs in the sketch K. It is\n",
            "clear that K1 and K2 contain all information about u1 and u2 from columns 1 to min(10, 8) = 8.\n",
            "Had we directly taken the ﬁrst Ds = 8 columns from the permuted data matrix, we would obtain the\n",
            "same non-zero entries as in K1 and K2, if we exclude elements in K1 and K2 whose IDs > Ds = 8.\n",
            "in this example, the element 10{8} in sketch K1 is excluded.\n",
            "On the other hand, since the columns are already permuted, any Ds columns constitute a random\n",
            "sample of size Ds. This means, by only looking at sketches K1 and K2, one can obtain a “random”\n",
            "sample of size Ds. By statistics theory, one can easily obtain an unbiased estimate of any linear\n",
            "summary statistics from a random sample. Since Ds is unknown until we look at K1 and K2 together,\n",
            "[13] viewed this as a random sample conditioning on Ds.\n",
            "Note that the Ds varies pairwise. When considering the rows u1 and u3, the sketches K1 and K3\n",
            "suggest their Ds = min(max(ID(K1)), max(ID(K3))) = min(10,12) = 10.\n",
            "\n",
            "In this study, we point out that, although the “conditioning” argument appeared intuitive, it is only a\n",
            "(good) heuristic. There are two ways to understand why this argument is not strictly correct.\n",
            "Consider a true random sample of size Ds, directly obtained from the ﬁrst Ds columns of the\n",
            "permuted data matrix. Assuming sparse data, elements at the Dsth column should be most likely\n",
            "zero. However, in the “conditional random sample” obtained from CRS, at least one element at the\n",
            "Dsth column is non-zero. Thus, the estimates of the original CRS are, strictly speaking, biased.\n",
            "For a more obvious example, we can consider two rows with exactly one non-zero entry in each row\n",
            "at the same column. The original CRS can not obtain an unbiased estimate unless Ds = D.\n",
            "3 CRS for Dynamic Data and Introduction to Stable Random Projections\n",
            "The original CRS was proposed for static data.\n",
            "In reality, the “data matrix” may be frequently\n",
            "updated. When data arrive in a streaming fashion, they often will not be stored (even on disks)[15].\n",
            "Thus, a one-pass algorithm is needed to compute and update distances for training. Learning with\n",
            "dynamic (or incremental) data has become an active topic of research, e.g., [5, 1].\n",
            "\n",
            "3.1 Dynamic/Streaming Data\n",
            "We ﬁrst consider only one data vector u of length D (viewed as one row in the data matrix). At each\n",
            "time t, there is an input stream st = (it, It), it ∈ [1, D] which updates u (denoted by ut) by\n",
            "\n",
            "ut[it] = H(ut−1[it], It),\n",
            "\n",
            "where It is the increment/decrement at time t and H is an updating function. The so-called Turnstile\n",
            "model [15] is extremely popular and assumes a linear updating function H, i.e.,\n",
            "\n",
            "(2)\n",
            "For example, ut[it] can represent the number of orders a “user” i has purchased up to time t, where\n",
            "a user may be identiﬁed by his/her IP address (i.e., i ∈ [1, D = 264]); It is the number of orders the\n",
            "user i orders (i.e., It > 0) or cancels (i.e., It < 0) at time t.\n",
            "\n",
            "ut[it] = ut−1[it] + It.\n",
            "\n",
            "5 0 0 1 0 7 0 0 0 8 0 1 0 8 0 2 12uuu31 2 3 4 5 6 7 8 9 10 11 12 13 14 15 160 9 2 0 6 0 0 7 0 5 0 0 4 0 0 13 0 4 0 0 2 0 0 0 8 0 0 3 0 0 12 0 213K : 1 {5} 4 {1} 6 {7} 10 {8} K : 2 {9} 3 {2} 5 {6} 8 {7}K : 2 {4} 5 {2} 9 {8} 12 {3} \fIn terms of the data matrix A ∈ Rn×D, we can view it to be a collection of n data streams.\n",
            "3.2 CRS for Streaming Data\n",
            "For each stream ut, we maintain a sketch K with length (i.e., capacity) k. Each entry of K is a tuple\n",
            "“ID{val}.” Initially, all entries are empty. The procedure for sketch construction works as follows:\n",
            "\n",
            "1. Generate a random permutation π : [1, D] → [1, D].\n",
            "2. For each st = (it, It), if π[it] > max(ID(K)) and the capacity of K is reached, do nothing.\n",
            "3. Suppose π[it] ≤ max(ID(K)) or the capacity of K is not reached. If an entry with ID =\n",
            "\n",
            "π[it] does not exist, insert a new entry. Otherwise, update that entry according to H.1\n",
            "\n",
            "4. Apply the procedure to each data stream using the same random permutation mapping π.\n",
            "\n",
            "Once sketches are constructed, the estimation procedure will be the same regardless whether the\n",
            "original data are dynamic or static. Thus, we will use static data to verify some estimators of CRS.\n",
            "\n",
            "(Symmetric) Stable Random Projections (SRP)\n",
            "\n",
            "3.3\n",
            "Since the method of (symmetric) stable random projections (SRP)[8, 10] has become a standard\n",
            "algorithm for data stream computations, we very brieﬂy introduce SRP for the sake of comparisons.\n",
            "The procedure of SRP is to multiply the data matrix A ∈ Rn×D by a random matrix R ∈ RD×k,\n",
            "whose entries are i.i.d. samples from a standard (symmetric) stable distribution S(p, 1), 0 < p ≤ 2.\n",
            "Consider two rows, u1 and u2, in A. By properties of stable distributions, the projected vectors\n",
            "v1 = RTu1 and v2 = RTu2 have i.i.d. stable entries, i.e., for j = 1 to k,\n",
            "\n",
            "(cid:195)\n",
            "\n",
            "(cid:33)\n",
            "\n",
            "D(cid:88)\n",
            "\n",
            "(cid:195)\n",
            "\n",
            "D(cid:88)\n",
            "\n",
            "(cid:33)\n",
            "\n",
            "v1,j ∼ S\n",
            "\n",
            "p, Fp =\n",
            "\n",
            "|u1,i|p\n",
            "\n",
            ",\n",
            "\n",
            "v1,j − v2,j ∼ S\n",
            "\n",
            "p, dp =\n",
            "\n",
            "|u1,i − u2,i|p\n",
            "\n",
            ".\n",
            "\n",
            "i=1\n",
            "\n",
            "i=1\n",
            "\n",
            "Thus, one can estimate an individual norm or distance from k samples. SRP is applicable to dy-\n",
            "namic/streaming data, provided the data follow the Turnstile model in (2). Because the Turnstile\n",
            "model is linear and matrix multiplication is also linear, one can conduct A × R incrementally.\n",
            "Compared with Conditional Random Sampling (CRS), SRP has an elegant mathematical deriva-\n",
            "tion, with various interesting estimators and rigorous sample complexity bounds, i.e., k can be pre-\n",
            "determined in fully rigorous fashion. The accuracy of SRP is not affected by heavy-tailed data.\n",
            "CRS, however, exhibits certain advantages over SRP:\n",
            "\n",
            "• CRS is “one-sketch-for-all”.\n",
            "\n",
            "The same sketch of CRS can approximate any linear\n",
            "summary statistics (1). SRP is limited to the lp norm and distance with 0 < p ≤ 2. One has\n",
            "to conduct SRP 10 times (and store 10 sets of sketches) if 10 different p values are needed.\n",
            "• CRS allows “term-weighting” in dynamic data.\n",
            "are often computed using weighted data (e.g., √\n",
            "In machine learning, the distances\n",
            "u1,i or log(1 + u1,i)), which is critical for\n",
            "good performance. For static data, one can ﬁrst term-weight the data before applying SRP.\n",
            "For dynamic data, however, there is no way to trace back the original data after projections.\n",
            "\n",
            "• CRS is not restricted to the Turnstile model.\n",
            "• CRS is not necessary less accurate,\n",
            "\n",
            "especially for sparse data or binary data.\n",
            "\n",
            "4 Approximating Hamming Norms in Dynamic Data\n",
            "Counting the Hamming norm (i.e., number of non-zeros) in an exceptionally long, dynamic vector\n",
            "has important applications[4, 15]. For example, if a vector ut records the numbers of items users\n",
            "have ordered, one meaningful question to ask may be “ how many distinct users are there?”\n",
            "The purpose of this section is three-fold. (1) This is the case we can rigorously analyze CRS and\n",
            "propose a truly unbiased estimator. (2) This analysis brings better insights and more reasonable\n",
            "estimators for pairs of data vectors. (3) In this case, despite its simplicity, CRS theoretically achieves\n",
            "similar accuracy as stable random projections (SRP). Empirically, CRS (slightly) outperforms SRP.\n",
            "1We leave it for particular applications to decide whether an entry updated to zero should be discarded or\n",
            "should be kept in the sketch. In reality, this case does not occur often. For example, the most important type of\n",
            "data streams[15] is “insertion-only,” meaning that the values will never decrease.\n",
            "\n",
            "\f4.1 The Proposed (Unbiased) Estimator and Variance\n",
            "Suppose we have obtained the sketch K. For example, consider the ﬁrst row in Figure 1: D = 16,\n",
            "k = 4 and the number of non-zeros f = 7. Lemma 1 (whose proof is omitted) proposes an unbiased\n",
            "estimator of f, denoted by ˆf, and a biased estimator based on the maximum likelihood, fmle.\n",
            "Lemma 1\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "(cid:180)\n",
            "\n",
            ",\n",
            "\n",
            "Z = max(ID(K)),\n",
            "\n",
            "E\n",
            "\n",
            "ˆf\n",
            "\n",
            "= f,\n",
            "\n",
            "D ≥ f ≥ k > 1\n",
            "\n",
            "D(k − 1)\n",
            "Z − 1\n",
            "ˆf\n",
            "< V U\n",
            "\n",
            "(cid:180)\n",
            "(cid:180)\n",
            "\n",
            "(cid:179)\n",
            "(cid:179)\n",
            "\n",
            "f =\n",
            "\n",
            "ˆf =\n",
            "\n",
            "Var\n",
            "\n",
            "Var\n",
            "\n",
            "ˆf\n",
            "\n",
            "> V L\n",
            "\n",
            "f = V U\n",
            "\n",
            ",\n",
            "\n",
            "D\n",
            "\n",
            "D − 1\n",
            "\n",
            "f 2 − f\n",
            "k − 2\n",
            "f − (k − 1)f (f − 1)(f − 2)D\n",
            "(k − 2)(k − 3)(D − 1)(D − 2)\n",
            "= f 2\n",
            "\n",
            "− (D − f )f\n",
            "D − 1\n",
            "(cid:179)\n",
            "ˆf\n",
            "Z − 1.\n",
            "\n",
            "(cid:180)\n",
            "\n",
            ",\n",
            "\n",
            "k + O\n",
            "\n",
            "(k > 2)\n",
            "\n",
            "(k > 3).\n",
            "\n",
            "(cid:161) 1\n",
            "\n",
            "k2\n",
            "\n",
            "(cid:162)\n",
            "\n",
            ".\n",
            "\n",
            "Assume f /D is small and k/f is also small, then Var\n",
            "\n",
            "The maximum likelihood estimator is ˆfmle = k(D+1)\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "(cid:180)\n",
            "\n",
            "/f 2 ≈ 1/k, independent of the data, the estimator ˆf actually has the worst-\n",
            "Note that, since Var\n",
            "case complexity bound similar to that of SRP[10], although the precise constant is not easy to obtain.\n",
            "\n",
            "ˆf\n",
            "\n",
            "4.2 The Approximation Using the Conditioning Argument\n",
            "max(ID(K))−1, appears to be the estimator for a hypergeometric\n",
            "Interestingly, this estimator, ˆf =\n",
            "random sample of size Ds = max(ID(K)) − 1. That is, suppose we randomly pick Ds balls (with-\n",
            "out replacement) from a pool of D balls and we observe that k(cid:48) balls are red; then a natural (and\n",
            "unbiased) estimator for the total number of red balls would be D\n",
            "Ds\n",
            "\n",
            "k(cid:48); here k(cid:48) = k − 1.\n",
            "\n",
            "D(k−1)\n",
            "\n",
            "This seems to imply that the “conditioning” argument in the original CRS in Section 2 is “correct”\n",
            "if we make a simple modiﬁcation by using the Ds which is the original Ds minus 1. While this is\n",
            "what we will recommend as the modiﬁed CRS, it is only a close approximation.\n",
            "Consider ˆfapp = ˆf, where we assume ˆfapp is the estimator for the hypergeometric distribution, then\n",
            "\n",
            "(cid:180)\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "ˆfapp|Ds = Z − 1\n",
            "\n",
            "(cid:180)\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "ˆfapp\n",
            "\n",
            "= E\n",
            "\n",
            "Var\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "=\n",
            "\n",
            "D2\n",
            "D2\n",
            "s\n",
            "ˆfapp|Ds\n",
            "\n",
            "Ds\n",
            "\n",
            "(cid:180)(cid:180)\n",
            "\n",
            "f\n",
            "D\n",
            "\n",
            "=\n",
            "\n",
            "1 − f\n",
            "D\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "D\n",
            "\n",
            "D − 1\n",
            "\n",
            "(cid:182)\n",
            "× D − Ds\n",
            "(cid:182)\n",
            "(cid:181)\n",
            "D − 1\n",
            "D\n",
            "\n",
            "E\n",
            "\n",
            "Z − 1\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "− 1\n",
            "\n",
            "f\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "1 − f\n",
            "D\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "=\n",
            "\n",
            "Df\n",
            "D − 1\n",
            "\n",
            "f\n",
            "\n",
            "k − 1\n",
            "\n",
            "− 1\n",
            "\n",
            "=\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "D − 1\n",
            "\n",
            "D\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "D\n",
            "Ds\n",
            "1 − f\n",
            "D\n",
            "\n",
            "− 1\n",
            "\n",
            "f\n",
            "\n",
            "(cid:182)(cid:181)\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "(3)\n",
            "\n",
            "1 − f\n",
            "D\n",
            "\n",
            "(cid:179)\n",
            "(cid:179)\n",
            "\n",
            "Var\n",
            "\n",
            "Var\n",
            "\n",
            "(cid:80)D\n",
            "4.3 Comparisons with Stable Random Projections (SRP)\n",
            "i=1 |ui|p, [4] proposed using SRP to approximate the\n",
            "Based on the observation that f = limp→0+\n",
            "(cid:80)D\n",
            "lp norm with very small p, as an approximation to f. For p → 0+, the recent work for SRP [10]\n",
            "proposed the harmonic mean estimator. Recall that after projections v = RTu ∈ Rk consists of\n",
            "(cid:195)\n",
            "(cid:195)\n",
            "i=1 |ui|p. The harmonic mean estimator is\n",
            "i.i.d. stable samples with scale parameter Fp =\n",
            "(cid:163)\n",
            "−πΓ(−2p) sin (πp)\n",
            "(cid:33)\n",
            "k −\n",
            "Γ(−p) sin\n",
            "(cid:162)(cid:164)2 − 1\n",
            "(cid:163)\n",
            "−−πΓ(−2p) sin (πp)\n",
            "\n",
            "(cid:161)\n",
            "(cid:80)k\n",
            "π Γ(−p) sin\n",
            "(cid:195)\n",
            "(cid:180)\n",
            "j=1 |vj|−p\n",
            "(cid:163)\n",
            "(cid:182)\n",
            "(cid:181)\n",
            "\n",
            "−πΓ(−2p) sin (πp)\n",
            "Γ(−p) sin\n",
            "→ 1,\n",
            "\n",
            "1\n",
            "k\n",
            "Γ(−p) sin\n",
            "\n",
            "(cid:162)(cid:164)2 − 1\n",
            "(cid:181)\n",
            "(cid:182)\n",
            "\n",
            "(cid:162)(cid:164)2 − 1 → 1.\n",
            "\n",
            "(cid:33)(cid:33)\n",
            "\n",
            "ˆFp,hm =\n",
            "\n",
            "= F 2\n",
            "p\n",
            "\n",
            "ˆFp,hm\n",
            "\n",
            "− 2\n",
            "\n",
            "1\n",
            "k2\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "(cid:161)\n",
            "\n",
            "(cid:162)\n",
            "\n",
            "(cid:161)\n",
            "\n",
            "(cid:161)\n",
            "\n",
            "+ O\n",
            "\n",
            "π\n",
            "2 p\n",
            "\n",
            "π\n",
            "2 p\n",
            "\n",
            "π\n",
            "2 p\n",
            "\n",
            "Var\n",
            "\n",
            ".\n",
            "\n",
            ",\n",
            "\n",
            "lim\n",
            "p→0+\n",
            "\n",
            "− 2\n",
            "π\n",
            "\n",
            "π\n",
            "2\n",
            "\n",
            "p\n",
            "\n",
            "lim\n",
            "p→0+\n",
            "\n",
            "Γ(−p) sin\n",
            "\n",
            "π\n",
            "2 p\n",
            "\n",
            "Denote this estimator by ˆfsrp (using p as small as possible), whose variance is Var\n",
            "which is roughly equivalent to the variance of ˆf, the unbiased estimator for CRS.\n",
            "We empirically compared CRS with SRP. Four word vectors were selected; entries of each vector\n",
            "record the numbers of occurrences of the word in D = 216 Web pages. The data are very heavy-\n",
            "tailed. The percentage of zero elements (i.e., sparsity) varies from 58% to 95%.\n",
            "Figure 2 presents the comparisons. (1): It is possible that CRS may outperform SRP non-negligibly.\n",
            "(2): The variance (3) based on the approximate “conditioning” argument is very accurate.\n",
            "(3): The\n",
            "unbiased estimator ˆf is more accurate than ˆfmle; the latter actually uses one more sample.\n",
            "\n",
            "ˆfsrp\n",
            "\n",
            "≈ f 2\n",
            "k ,\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "(cid:180)\n",
            "\n",
            "\fFigure 2: Comparing CRS with SRP for approximating Hamming norms in Web crawl data (four\n",
            "word vectors), using the normalized mean square errors (MSE, normalized by f 2). “CRS” and\n",
            "“CRS+mle” respectively correspond to ˆf and ˆfmle, derived in Lemma 1. ”SRP” corresponds to the\n",
            "harmonic mean estimator of SRP using p = 0.04. “1/k” is the theoretical asymptotic variance of\n",
            "both CRS and SRP. The curve labeled ”Approx. Var” is the approximate variance in (3).\n",
            "\n",
            "5 The Modiﬁed CRS Estimation Procedure\n",
            "The modiﬁed CRS estimation procedure is based on the theoretical analysis for using CRS to ap-\n",
            "proximate Hamming norms. Suppose we are interested in the distance between rows u1 and u2 and\n",
            "we have access to sketches K1 and K2. Our suggested “equivalent” sample size Ds would be\n",
            "\n",
            "Ds = min{Z1 − 1, Z2 − 1},\n",
            "\n",
            "Z1 = max(ID(K1), Z2 = max(ID(K2).\n",
            "\n",
            "(4)\n",
            "\n",
            "We should not include elements in K1 and K2 whose IDs are larger than Ds\n",
            "Consider K1 and K2 in Figure 1, the modiﬁed CRS adopts Ds = min(10− 1, 8− 1) = min(9, 7) =\n",
            "7. Removing 10{8} from K1 and 8{7} from K2, we obtain a sample for u1 and u2:\n",
            "˜u2,2 = 9, ˜u2,3 = 2, ˜u2,5 = 6.\n",
            "\n",
            "˜u1,1 = 5, ˜u1,4 = 1, ˜u1,6 = 7,\n",
            "\n",
            "All other sample entries are zero: ˜u1,2 = ˜u1,3 = ˜u1,5 = ˜u1,7 = 0, ˜u2,1 = ˜u2,4 = ˜u2,6 = ˜u2,7 = 0.\n",
            "\n",
            "(cid:80)D\n",
            "i=1 g (u1,i, u2,i), and assume that, conditioning on Ds, the sample {˜u1,j, ˜u2,j}Ds\n",
            "\n",
            "5.1 A Generic Estimator and Approximate Variance\n",
            "Rigorous theoretical analysis on one pair of sketches is difﬁcult. We resort to the approximate\n",
            "“conditioning” argument using the modiﬁed Ds in (4). We consider a generic distance dg(u1, u2) =\n",
            "j=1 is exactly\n",
            "equivalent to the sample from randomly selected Ds columns without replacement. Under this\n",
            "assumption, an “unbiased” estimator of dg(u1, u2) (and two special cases) would be\n",
            "\n",
            "ˆdg(u1, u2) =\n",
            "\n",
            "D\n",
            "Ds\n",
            "\n",
            "g(˜u1,j, ˜u2,j),\n",
            "\n",
            "ˆdp =\n",
            "\n",
            "D\n",
            "Ds\n",
            "\n",
            "|˜u1,j − ˜u2,j|p,\n",
            "\n",
            "ˆdχ2 =\n",
            "\n",
            "D\n",
            "Ds\n",
            "\n",
            "(˜u1,j − ˜u2,j)2\n",
            "˜u1,j + ˜u2,j\n",
            "\n",
            ".\n",
            "\n",
            "Ds(cid:88)\n",
            "\n",
            "j=1\n",
            "\n",
            "A generic (approximate) variance formula can be obtained as follows:\n",
            "\n",
            "Var\n",
            "\n",
            "ˆdg(u1, u2)|Ds\n",
            "\n",
            "Ds\n",
            "\n",
            "E\n",
            "\n",
            "g2(˜u1,j , ˜u2,j )\n",
            "\n",
            "− E2 (g(˜u1,j , ˜u2,j ))\n",
            "\n",
            "D(cid:88)\n",
            "\n",
            "i=1\n",
            "\n",
            "(cid:180)\n",
            " 1\n",
            "\n",
            "D\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "Ds\n",
            "\n",
            "D − Ds\n",
            "D − 1\n",
            "\n",
            "=\n",
            "\n",
            "D2\n",
            "D2\n",
            "s\n",
            "\n",
            "Var\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "× D2\n",
            "D2\n",
            "s\n",
            "\n",
            "g2(u1,i, u2,i) −\n",
            "\n",
            "≈ D − Ds\n",
            "D(cid:88)\n",
            "D − 1\n",
            "(cid:180)\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "i=1\n",
            "\n",
            "(cid:179)\n",
            "\n",
            ",\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "ˆdg(u1, u2)\n",
            "\n",
            "≈ E\n",
            "\n",
            "Var\n",
            "\n",
            "ˆdg(u1, u2)|Ds\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "(cid:181)\n",
            "(cid:181)\n",
            "(cid:181)\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "(cid:189)\n",
            "(cid:189)\n",
            "\n",
            "=\n",
            "\n",
            "D\n",
            "\n",
            "D − 1\n",
            "\n",
            "≈ D\n",
            "\n",
            "D − 1\n",
            "\n",
            "=\n",
            "\n",
            "D\n",
            "\n",
            "D − 1\n",
            "\n",
            "E\n",
            "\n",
            "max{ D\n",
            "\n",
            "Z1 − 1\n",
            "\n",
            "D\n",
            "\n",
            "Z2 − 1\n",
            "\n",
            "}\n",
            "\n",
            "max\n",
            "\n",
            "E\n",
            "\n",
            "D\n",
            "\n",
            "Z1 − 1\n",
            "\n",
            ", E\n",
            "\n",
            "D\n",
            "\n",
            "Z2 − 1\n",
            "\n",
            "max\n",
            "\n",
            "f1\n",
            "\n",
            "k1 − 1\n",
            "\n",
            ",\n",
            "\n",
            "f2\n",
            "\n",
            "k2 − 1\n",
            "\n",
            "− 1\n",
            "\n",
            "(cid:181)\n",
            "(cid:190)\n",
            "\n",
            "(cid:179)\n",
            "(cid:195)\n",
            "\n",
            "(cid:179)\n",
            "D(cid:88)\n",
            "\n",
            "1\n",
            "D\n",
            "\n",
            "(cid:180)\n",
            "\n",
            "(cid:33)2 =\n",
            "(cid:181)\n",
            "(cid:181)\n",
            "(cid:33)\n",
            "\n",
            "E\n",
            "\n",
            "g(u1,i, u2,i)\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "=\n",
            "\n",
            "D\n",
            "\n",
            "i=1\n",
            "\n",
            "− 1\n",
            "\n",
            "(cid:180)(cid:180)\n",
            "(cid:182)(cid:195)\n",
            "D − 1\n",
            "dg2 − d2\n",
            "(cid:182)(cid:195)\n",
            "(cid:182)(cid:190)\n",
            "dg2 − d2\n",
            "(cid:33)\n",
            "(cid:182)(cid:195)\n",
            "dg2 − d2\n",
            "\n",
            "− 1\n",
            "\n",
            "g\n",
            "D\n",
            "\n",
            "g\n",
            "D\n",
            "\n",
            ".\n",
            "\n",
            "g\n",
            "D\n",
            "\n",
            "D\n",
            "Ds\n",
            "\n",
            "(cid:33)\n",
            "\n",
            "Ds(cid:88)\n",
            "\n",
            "j=1\n",
            "\n",
            "(cid:180)\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "(cid:182)(cid:195)\n",
            "dg2 − d2\n",
            "(cid:33)\n",
            "\n",
            "g\n",
            "D\n",
            "\n",
            "− 1\n",
            "\n",
            "D\n",
            "Ds\n",
            "\n",
            "(cid:182)(cid:195)\n",
            "dg2 − d2\n",
            "\n",
            "g\n",
            "D\n",
            "\n",
            "D\n",
            "\n",
            "D − 1\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "− 1\n",
            "\n",
            "(cid:33)\n",
            "\n",
            ".\n",
            "\n",
            "(5)\n",
            "\n",
            "Here, k1 and k2 are the sketch sizes of K1 and K2, respectively, f1 and f2 are the numbers of non-\n",
            "zeros in the original data, u1, u2, respectively. We have used the results in Lemma 1 and a common\n",
            "statistical approximation: E(max(x, y)) ≈ max (E(x), E(y)).\n",
            "\n",
            "31020304010−1100kStandardized MSETHIS CRSCRS+mleSRP1/kApprox. Var31020304010−1100kStandardized MSEHAVE CRSCRS+mleSRP1/kApprox. Var31020304010−1100kStandardized MSEADDRESS CRSCRS+mleSRP1/kApprox. Var31020304010−1100kStandardized MSECUSTOMER CRSCRS+mleSRP1/kApprox. Var\f(cid:110)\n",
            "\n",
            "(cid:111)\n",
            "\n",
            "f1\n",
            "k1−1 ,\n",
            "\n",
            "From (5), we know the variance is affected by two factors.\n",
            "If the data are very sparse, i.e.,\n",
            "max\n",
            "f2\n",
            "is small, then the variance also tends to be small. If the data are heavy-tailed,\n",
            "k2−1\n",
            "i.e., Ddg2 (cid:192) d2\n",
            "g, then the variance tends to be large. Text data are often highly sparse and heavy-\n",
            "tailed; but machine learning applications often need to use the weighted data (i.e., taking logarithm\n",
            "or binary quantization). This is why we expect CRS will be successful in real applications, although\n",
            "it in general does not have the worst-case performance guarantees.\n",
            "The next two subsections apply CRS to estimating the Hamming distance and the χ2 distance.\n",
            "Empirical studies [3, 7, 9] have demonstrated that, in text and image data, using the Hamming\n",
            "distance or the χ2 distance for kernel SVMs achieved good performance.\n",
            "\n",
            "5.2 Estimating the Hamming Distance\n",
            "Following the deﬁnition of Hamming distance in [4]: h (u1, u2) =\n",
            "mate h using the modiﬁed CRS procedure, denoted by ˆh. The approximate variance (5) becomes\n",
            "\n",
            "(cid:80)D\n",
            "i=1 1{u1,i − u2,i (cid:54)= 0}, we esti-\n",
            "(cid:182)(cid:181)\n",
            "\n",
            "(cid:182)\n",
            "\n",
            "(cid:190)\n",
            "\n",
            "(cid:189)\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "≈ D\n",
            "\n",
            "D − 1\n",
            "\n",
            "max\n",
            "\n",
            "f1\n",
            "\n",
            "k1 − 1\n",
            "\n",
            ",\n",
            "\n",
            "f2\n",
            "\n",
            "k2 − 1\n",
            "\n",
            "− 1\n",
            "\n",
            "h − h2\n",
            "D\n",
            "\n",
            ".\n",
            "\n",
            "(6)\n",
            "\n",
            "(cid:179)\n",
            "\n",
            "(cid:180)\n",
            "\n",
            "Var\n",
            "\n",
            "ˆh\n",
            "\n",
            "We also apply SRP using small p and its most accurate harmonic mean estimator[10]. The empirical\n",
            "comparisons in Figure 3 verify two points. (1): CRS can be considerably more accurate than SRP for\n",
            "estimating Hamming distances in [4]. (2): The approximate variance formula (6) is very accurate.\n",
            "\n",
            "Figure 3: Approximating Hamming distances (h) using two pairs of words. The results are presented\n",
            "in terms of the normalized (by h2) MSE. The curves labeled “Approx. Var” correspond to the\n",
            "approximate variance of CRS in (6).\n",
            "\n",
            "(cid:80)D\n",
            "In this example, the seemingly impressive improvement of CRS over SRP is actually due to that we\n",
            "used the deﬁnition of Hamming distance in [4]. An alternative deﬁnition of Hamming distance is\n",
            "i=1[1{u1,i (cid:54)= 0 and u2,i = 0} + 1{u1,i = 0 and u2,i (cid:54)= 0}], which is basically the\n",
            "h(u1, u2) =\n",
            "lp distance after a binary term-weighting. As we have commented, if using SRP in dynamic data,\n",
            "term-weighting is not possible; thus we only experimented with the deﬁnition in [4].\n",
            "\n",
            "5.3 Estimating the χ2 Distance\n",
            "\n",
            "i=1\n",
            "\n",
            "i=1(u1,i + u2,i)2.\n",
            "which is affected only by the second moments, because\n",
            "There are proved negative results [6] that in the worst-case no efﬁcient algorithms exist for approx-\n",
            "imating the χ2 distances. CRS does not provide any worst-case guarantees; its performance relies\n",
            "on the assumption that the data are often reasonably sparse and the second moments should be\n",
            "reasonably bounded in machine learning applications.\n",
            "Figure 4 presents some empirical study, using the same four words, plus the UCI Dexter data. Even\n",
            "though the four words are fairly common (i.e., not very sparse) and they are heavy-tailed (no term-\n",
            "weighting was applied), CRS still achieved good performance in terms of the normalized MSE (e.g.,\n",
            "≤ 0.1) at reasonably small k. And again, the approximate variance formula (7) is accurate.\n",
            "Results in the Dexter data set (which is more realistic for machine learning) are encouraging. Only\n",
            "about k = 10 is needed to achieve small MSE.\n",
            "\n",
            "We apply CRS to estimating the χ2 distance between u1 and u2: dχ2 (u1, u2) =\n",
            "According to (5), the estimation variance should be approximately\n",
            "\n",
            "i=1\n",
            "\n",
            "(cid:181)\n",
            "\n",
            "(cid:189)\n",
            "\n",
            "(cid:190)\n",
            "\n",
            "D\n",
            "\n",
            "D − 1\n",
            "\n",
            "max\n",
            "\n",
            "f1\n",
            "\n",
            "k1 − 1\n",
            "\n",
            ",\n",
            "\n",
            "f2\n",
            "\n",
            "k2 − 1\n",
            "\n",
            "− 1\n",
            "\n",
            "(cid:80)D\n",
            "(cid:182)(cid:195)\n",
            "(cid:33)\n",
            "D(cid:88)\n",
            "(u1,i − u2,i)4\n",
            "(u1,i + u2,i)2 − d2\n",
            "(u1,i+u2,i)2 ≤ (cid:80)D\n",
            "(cid:80)D\n",
            "\n",
            "(u1,i−u2,i)4\n",
            "\n",
            "χ2\n",
            "D\n",
            "\n",
            "i=1\n",
            "\n",
            ",\n",
            "\n",
            "(u1,i−u2,i)2\n",
            "u1,i+u2,i\n",
            "\n",
            ".\n",
            "\n",
            "(7)\n",
            "\n",
            "1020304010−210−1100kStandardized MSE THIS − HAVECRSApprox. VarSRP1020304010−210−1100kStandardized MSE ADDRESS − CUSTOMERCRSApprox. VarSRP\fFigure 4: Left two panels: CRS for approximating the χ2 distance using two pairs of words (D =\n",
            "216). The curves report the normalized MSE and the approximate variance in (7).\n",
            "Right-most panel: The Dexter data, D = 20000, with 300 data points. We estimate all pairwise (i.e.,\n",
            "44850 pairs) χ2 distances using CRS. The three curves report the quantiles of normalized MSEs.\n",
            "\n",
            "6 Conclusion\n",
            "The ubiquitous phenomenon of massive, high-dimensional, and possibly dynamic data, has brought\n",
            "in serious challenges. It is highly desirable to achieve compact data presentation and efﬁciently\n",
            "computing and retrieving summary statistics, in particular, various types of distances. Conditional\n",
            "Random Sampling (CRS) provides a simple and effective mechanism to achieve this goal.\n",
            "Compared with other “main stream” sketching algorithms such as stable random projections (SRP),\n",
            "the major advantage of CRS is that it is “one-sketch-for-all,” meaning that the same set of sketches\n",
            "can approximate any linear summary statistics. This would be very convenient in practice.\n",
            "The major disadvantage of CRS is that it relies heavily on the data sparsity and also on the assump-\n",
            "tion that in machine learning applications the “worst-case” data distributions are often avoided (e.g.,\n",
            "through term-weighting). Also, the theoretical analysis is difﬁcult, despite it is a simple algorithm.\n",
            "Originally based on a heuristic argument, the preliminary version of CRS, was proposed as a tool\n",
            "for computing pairwise l2 and l1 distances in static data. This paper provides a partial theoretical\n",
            "justiﬁcation of CRS and various modiﬁcations, to make the algorithm more rigorous and to extend\n",
            "CRS for handling dynamic/streaming data. We demonstrate, empirically and theoretically, the ef-\n",
            "fectiveness of CRS in approximating the Hamming norms/distances and the χ2 distances.\n",
            "Acknowledgement\n",
            "Ping Li is partially supported by grant DMS-0808864 from the National Science Foundation, and\n",
            "a gift from Microsoft. Trevor Hastie was partially supported by grant DMS-0505676 from the\n",
            "National Science Foundation, and grant 2R01 CA 72028-07 from the National Institutes of Health.\n",
            "References\n",
            "[1] Charu C. Aggarwal, Jiawei Han, Jianyong Wang, and Philip S. Yu. On demand classiﬁcation of data streams. In KDD, 503–508, 2004.\n",
            "[2] L´eon Bottou, Olivier Chapelle, Dennis DeCoste, and Jason Weston, editors. Large-Scale Kernel Machines. The MIT Press, 2007.\n",
            "[3] Olivier Chapelle, Patrick Haffner, and Vladimir N. Vapnik. Support vector machines for histogram-based image classiﬁcation. IEEE\n",
            "\n",
            "Trans. Neural Networks, 10(5):1055–1064, 1999.\n",
            "\n",
            "[4] Graham Cormode, Mayur Datar, Piotr Indyk, and S. Muthukrishnan. Comparing data streams using hamming norms (how to zero in).\n",
            "\n",
            "IEEE Transactions on Knowledge and Data Engineering, 15(3):529–540, 2003.\n",
            "\n",
            "[5] Carlotta Domeniconi and Dimitrios Gunopulos. Incremental support vector machine construction. In ICDM, pages 589–592, 2001.\n",
            "[6] Sudipto Guha, Piotr Indyk, and Andrew McGregor. Sketching infomration divergence. In COLT, pages 424–438, 2007.\n",
            "[7] M. Hein and O. Bousquet. Hilbertian metrics and positive deﬁnite kernels on probability measures. In AISTATS, pages 136–143, 2005.\n",
            "[8] Piotr Indyk. Stable distributions, pseudorandom generators, embeddings, and data stream computation. J. of ACM, 53(3):307–323, 2006.\n",
            "\n",
            "CIVR, pages 494–501, 2007.\n",
            "\n",
            "[9] Yugang Jiang, Chongwah Ngo, and Jun Yang. Towards optimal bag-of-features for object categorization and semantic video retrieval. In\n",
            "[10] Ping Li. Estimators and tail bounds for dimension reduction in lα (0 < α ≤ 2) using stable random projections. In SODA, 2008.\n",
            "[11] Ping Li. Compressed Counting. In SODA, 2009.\n",
            "[12] Ping Li and Kenneth W. Church. A sketch algorithm for estimating two-way and multi-way Associations. Computational Linguistics,\n",
            "\n",
            "33(3):305-354, 2007. Preliminary results appeared in HLT/EMNLP, 2005.\n",
            "\n",
            "[13] Ping Li, Kenneth W. Church, and Trevor J. Hastie. Conditional random sampling: A sketch-based sampling technique for sparse data. In\n",
            "\n",
            "NIPS, pages 873–880, 2007.\n",
            "\n",
            "[14] Ping Li. Computationally efﬁcient estimators for dimension reductions using stable random projections. In ICDM, 2008.\n",
            "[15] S. Muthukrishnan. Data streams: Algorithms and applications. Found. and Trends in Theoretical Computer Science, 1:117–236, 2 2005.\n",
            "\n",
            "[16] John C. Platt. Using analytic QP and sparseness to speed training of support vector machines. In NIPS, pages 557–563, 1998.\n",
            "[17] Bernhard Sch¨olkopf and Alexander J. Smola. Learning with Kernels. The MIT Press, 2002.\n",
            "\n",
            "0102040608010010−210−1100kStandardized MSE THIS − HAVECRSApprox. Var0102040608010010−1100kStandardized MSE ADDRESS − CUSTOMERCRSApprox. Var35101520253010−210−1100101kNormalized MSE Dexter10%50%90%\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "pQLySGFGpnpW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "d528051f44ab4bd983fc46b86580090d",
            "b0931a363f024add845f31ddfdc9a719",
            "69c38902813e4b609f9128278fc12c13",
            "d8b8075438d24ff79ca8d244ff78c33f",
            "b684fa47deb64333818223fdb6f6b403",
            "b66e8688846846309ad2c48343ccda85",
            "f2e6a3859ef742d09cbccb482ca6c1fe",
            "0064881177d64029b518dfe99badee90",
            "f18713f617e74db184d9744fa2c008ed",
            "4db246b0cca64d8f884f791f8267656c",
            "a931ad1bb14b4508881760c6002cc701",
            "d79e61b3009d4be199f73a31da2173d7",
            "5e8cc046cdbc4bfa8336c8d29f1ef9de",
            "622ec5711c8c4c85a409c6c91fff11c5"
          ]
        },
        "outputId": "b92f5296-13b7-4ed6-ca73-f89a7d98c132"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d528051f44ab4bd983fc46b86580090d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install git-lfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVpTGdxAsTfZ",
        "outputId": "44c1e134-cd25-4fd0-af2c-44397f63ec0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import create_optimizer, AdamWeightDecay\n",
        "from transformers import AutoConfig\n",
        "from transformers import T5Model\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "\n",
        "metric = load_metric(\"rouge\")\n",
        "tokenizer = 0\n",
        "prefix = \"summarize: \"\n",
        "max_input_length = 1024\n",
        "max_target_length = 128\n",
        "\n",
        "\n",
        "#adds padding to input before traing the model on the dataset\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"full_text\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"abstract\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "\n",
        "#tokenizer for the dataset\n",
        "def my_tokenize(model_checkpoint):\n",
        "  global tokenizer\n",
        "\n",
        "  sum = dataset_tuning\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "  tokenized_sum = sum.map(preprocess_function, batched=True)\n",
        "\n",
        "  return (tokenizer, tokenized_sum)\n",
        "\n",
        "\n",
        "#create new summerization model\n",
        "def get_model(model_checkpoint, tokenizer):\n",
        "  #make a model that is not pre-trained\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(\"Dagar/t5-small-science-papers\")\n",
        "\n",
        "  data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "  return (model, data_collator)\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "\n",
        "#set hyper paramaters\n",
        "#change hyper paramters for better trained model\n",
        "def get_my_hyper_params(model_checkpoint, my_epochs, floating_point):\n",
        "  batch_size = 16\n",
        "  model_name = model_checkpoint\n",
        "  args = Seq2SeqTrainingArguments(\n",
        "      f\"{model_name}-science-papers-NIPS\",\n",
        "      evaluation_strategy = \"epoch\",\n",
        "      learning_rate=2e-5,\n",
        "      per_device_train_batch_size=batch_size,\n",
        "      per_device_eval_batch_size=batch_size,\n",
        "      weight_decay=0.01,\n",
        "      save_total_limit=20,\n",
        "      num_train_epochs=my_epochs,\n",
        "      predict_with_generate=True,\n",
        "      fp16=floating_point,\n",
        "      push_to_hub=True,\n",
        "  )\n",
        "\n",
        "  return args\n",
        "\n",
        "#make the trainer\n",
        "def get_trainer(model, tokenizer, tokenized_sum, data_collator, training_args):\n",
        "  trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_sum[\"train\"],\n",
        "    eval_dataset=tokenized_sum[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        "\t)\n",
        "  return trainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "b4a7b00c72d74d808f0246b4caaec996",
            "e4fd22bdb135450980a38471eb41efdc",
            "01f48dc1e3004ff2952280ad40d7b9e4",
            "fdb1a9f1930346239aba4c0866afc6bf",
            "5b99aec09c054d0399d07ee4787b4ad3",
            "e5ed19de405f4b8cb58e15a5ec8928e5",
            "6188f686343e405298dfd79b21d18d97",
            "9fff64806fca4d6aa7fd9c8ba8bff959",
            "b435e27b823e411e9b8f775ea4c0137c",
            "a1aeef6c385b42c484973100866f177a",
            "c66c315361fd42acb1324da77f8a7179"
          ]
        },
        "id": "MnYweUOssjUB",
        "outputId": "d0c54131-0be2-4ea7-cb06-ad925c6cb171"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4a7b00c72d74d808f0246b4caaec996"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_train_model():\n",
        "  model_name = \"t5-small\"\n",
        "  epochs = 1\n",
        "  floating_point = True\n",
        "\n",
        "  token_tuple = my_tokenize(model_name)\n",
        "\n",
        "  model_tuple = get_model(model_name, token_tuple[0])\n",
        "\n",
        "  params = get_my_hyper_params(model_name, epochs, floating_point)\n",
        "\n",
        "  trainer = get_trainer(model_tuple[0], token_tuple[0], token_tuple[1], model_tuple[1], params)\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "HFsePMT9s2p9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = my_train_model()"
      ],
      "metadata": {
        "id": "pQTyBNZQu0jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "kdtCJqRKu3Q5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}